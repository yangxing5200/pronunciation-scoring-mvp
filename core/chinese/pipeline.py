"""
Chinese Pronunciation Scoring Pipeline - Enhanced Version

æ•´åˆæ‰€æœ‰ 9 ä¸ªä»»åŠ¡çš„å®Œæ•´å‘éŸ³è¯„åˆ†æµæ°´çº¿ã€‚
å¢å¼ºåŠŸèƒ½ï¼š
- è‡ªåŠ¨ç”Ÿæˆæ ‡å‡†éŸ³ï¼ˆå¦‚æœ TTS å¯ç”¨ï¼‰
- ä½¿ç”¨ FunASR è¿›è¡Œä¸­æ–‡è¯†åˆ«ï¼ˆæ›¿ä»£ WhisperXï¼‰
- ä½¿ç”¨ F0 æ›²çº¿åˆ†æè¿›è¡Œå£°è°ƒè¯„åˆ†ï¼ˆæ›¿ä»£éšæœº MLPï¼‰
- ä½¿ç”¨è§„åˆ™æ–¹æ³•è¿›è¡Œé”™è¯¯åˆ†ç±»ï¼ˆæ›¿ä»£éšæœº MLPï¼‰
"""

from typing import Dict, List, Optional
from pathlib import Path
import warnings
import logging
import tempfile
import os

from .pinyin_mapper import PinyinMapper
from .audio_aligner import ChineseAudioAligner
from .audio_slicer import AudioSlicer
from .acoustic_scorer import AcousticScorer
from .tone_scorer import ToneScorer
from .duration_scorer import DurationScorer
from .pause_scorer import PauseScorer
from .error_classifier import ErrorClassifier
from .final_scorer import FinalScorer

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)


class ChineseScoringPipeline:
    """
    å®Œæ•´çš„ä¸­æ–‡å‘éŸ³è¯„åˆ†æµæ°´çº¿ã€‚
    
    æ‰§è¡Œ 9 ä¸ªä»»åŠ¡ï¼š
    1. æ‹¼éŸ³æ˜ å°„ (PinyinMapper)
    2. éŸ³é¢‘å¯¹é½ (ChineseAudioAligner) - FunASR
    3. éŸ³é¢‘åˆ‡ç‰‡ (AudioSlicer)
    4. å£°å­¦è¯„åˆ† (AcousticScorer) - WavLM
    5. å£°è°ƒè¯„åˆ† (ToneScorer) - F0 æ›²çº¿åˆ†æ
    6. æ—¶é•¿è¯„åˆ† (DurationScorer)
    7. åœé¡¿è¯„åˆ† (PauseScorer)
    8. é”™è¯¯åˆ†ç±» (ErrorClassifier) - è§„åˆ™æ–¹æ³•
    9. ç»¼åˆè¯„åˆ† (FinalScorer)
    """
    
    def __init__(
        self,
        device: Optional[str] = None,
        enable_gpu: bool = True,
        tts_generator: Optional[callable] = None,
        reference_audio_dir: Optional[str] = None
    ):
        """
        åˆå§‹åŒ–æµæ°´çº¿ã€‚
        
        Args:
            device: ä½¿ç”¨çš„è®¾å¤‡ ('cuda' æˆ– 'cpu')ï¼ŒNone æ—¶è‡ªåŠ¨æ£€æµ‹
            enable_gpu: æ˜¯å¦å¯ç”¨ GPU åŠ é€Ÿ
            tts_generator: TTS ç”Ÿæˆå‡½æ•°ï¼Œç”¨äºè‡ªåŠ¨ç”Ÿæˆæ ‡å‡†éŸ³
                          ç­¾å: tts_generator(text: str, output_path: str) -> bool
            reference_audio_dir: é¢„å½•åˆ¶æ ‡å‡†éŸ³çš„ç›®å½•ï¼ˆå¯é€‰ï¼‰
        """
        # è®¾å¤‡æ£€æµ‹
        if device is None and enable_gpu:
            try:
                import torch
                device = "cuda" if torch.cuda.is_available() else "cpu"
            except ImportError:
                device = "cpu"
        elif device is None:
            device = "cpu"
        
        self.device = device
        self.tts_generator = tts_generator
        self.reference_audio_dir = Path(reference_audio_dir) if reference_audio_dir else None
        
        # åˆå§‹åŒ–æ‰€æœ‰æ¨¡å—
        self.pinyin_mapper = PinyinMapper()
        self.audio_aligner = ChineseAudioAligner(device=device)
        self.audio_slicer = AudioSlicer()
        self.acoustic_scorer = AcousticScorer(device=device)
        self.tone_scorer = ToneScorer(device=device)
        self.duration_scorer = DurationScorer()
        self.pause_scorer = PauseScorer()
        self.error_classifier = ErrorClassifier(device=device)
        self.final_scorer = FinalScorer()
        
        # æ ‡å‡†éŸ³ç¼“å­˜ï¼ˆé¿å…é‡å¤ç”Ÿæˆï¼‰
        self._reference_cache: Dict[str, str] = {}
        
        # ä¸´æ—¶æ–‡ä»¶ç›®å½•
        self._temp_dir = Path(tempfile.gettempdir()) / "chinese_scoring"
        self._temp_dir.mkdir(parents=True, exist_ok=True)
        
        self.models_loaded = False
    
    def set_tts_generator(self, tts_generator: callable):
        """
        è®¾ç½® TTS ç”Ÿæˆå™¨ã€‚
        
        Args:
            tts_generator: TTS ç”Ÿæˆå‡½æ•°
                          ç­¾å: tts_generator(text: str, output_path: str) -> bool
        """
        self.tts_generator = tts_generator
        logger.info("TTS ç”Ÿæˆå™¨å·²è®¾ç½®")
    
    def load_models(self, model_size: str = "base"):
        """
        åŠ è½½æ‰€æœ‰å¿…éœ€çš„æ¨¡å‹ã€‚
        
        Args:
            model_size: æ¨¡å‹å¤§å°ï¼ˆç”¨äº WhisperX å¤‡é€‰ï¼‰
        """
        if self.models_loaded:
            return
        
        logger.info("æ­£åœ¨åŠ è½½ä¸­æ–‡å‘éŸ³è¯„åˆ†æ¨¡å‹...")
        
        # 1. åŠ è½½éŸ³é¢‘å¯¹é½æ¨¡å‹ (FunASR)
        if self.audio_aligner.is_available():
            try:
                self.audio_aligner.load_models(model_size)
            except Exception as e:
                warnings.warn(f"éŸ³é¢‘å¯¹é½æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        
        # 2. åŠ è½½å£°å­¦è¯„åˆ†æ¨¡å‹ (WavLM)
        if self.acoustic_scorer.is_available():
            try:
                self.acoustic_scorer.load_model()
            except Exception as e:
                warnings.warn(f"å£°å­¦è¯„åˆ†æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        
        # 3. åŠ è½½å£°è°ƒè¯„åˆ†æ¨¡å—
        if self.tone_scorer.is_available():
            try:
                self.tone_scorer.load_models()
            except Exception as e:
                warnings.warn(f"å£°è°ƒè¯„åˆ†æ¨¡å—åŠ è½½å¤±è´¥: {e}")
        
        # 4. åŠ è½½é”™è¯¯åˆ†ç±»æ¨¡å—
        if self.error_classifier.is_available():
            try:
                self.error_classifier.load_models()
            except Exception as e:
                warnings.warn(f"é”™è¯¯åˆ†ç±»æ¨¡å—åŠ è½½å¤±è´¥: {e}")
        
        self.models_loaded = True
        logger.info(f"æ¨¡å‹åŠ è½½å®Œæˆ (è®¾å¤‡: {self.device})")
    
    def _get_or_generate_reference_audio(
        self,
        reference_text: str,
        force_generate: bool = False
    ) -> Optional[str]:
        """
        è·å–æˆ–ç”Ÿæˆæ ‡å‡†éŸ³éŸ³é¢‘ã€‚
        
        ä¼˜å…ˆçº§ï¼š
        1. ç¼“å­˜ä¸­çš„æ ‡å‡†éŸ³
        2. é¢„å½•åˆ¶çš„æ ‡å‡†éŸ³æ–‡ä»¶
        3. TTS ç”Ÿæˆçš„æ ‡å‡†éŸ³
        
        Args:
            reference_text: å‚è€ƒæ–‡æœ¬
            force_generate: æ˜¯å¦å¼ºåˆ¶é‡æ–°ç”Ÿæˆ
        
        Returns:
            æ ‡å‡†éŸ³éŸ³é¢‘è·¯å¾„ï¼Œæˆ– None å¦‚æœä¸å¯ç”¨
        """
        # ç”Ÿæˆç¼“å­˜é”®
        cache_key = reference_text.strip()
        
        # 1. æ£€æŸ¥ç¼“å­˜
        if not force_generate and cache_key in self._reference_cache:
            cached_path = self._reference_cache[cache_key]
            if Path(cached_path).exists():
                logger.debug(f"ä½¿ç”¨ç¼“å­˜çš„æ ‡å‡†éŸ³: {cached_path}")
                return cached_path
        
        # 2. æ£€æŸ¥é¢„å½•åˆ¶çš„æ ‡å‡†éŸ³
        if self.reference_audio_dir and self.reference_audio_dir.exists():
            # å°è¯•å¤šç§å‘½åæ–¹å¼
            possible_names = [
                f"{cache_key}.wav",
                f"{cache_key.replace(' ', '_')}.wav",
                f"ref_{hash(cache_key) % 10000}.wav"
            ]
            
            for name in possible_names:
                ref_path = self.reference_audio_dir / name
                if ref_path.exists():
                    self._reference_cache[cache_key] = str(ref_path)
                    logger.debug(f"ä½¿ç”¨é¢„å½•åˆ¶çš„æ ‡å‡†éŸ³: {ref_path}")
                    return str(ref_path)
        
        # 3. ä½¿ç”¨ TTS ç”Ÿæˆ
        if self.tts_generator is not None:
            try:
                # ç”Ÿæˆè¾“å‡ºè·¯å¾„
                safe_filename = "".join(c if c.isalnum() else "_" for c in cache_key[:20])
                output_path = self._temp_dir / f"ref_{safe_filename}_{hash(cache_key) % 10000}.wav"
                
                logger.info(f"æ­£åœ¨ç”Ÿæˆæ ‡å‡†éŸ³: {reference_text[:20]}...")
                
                success = self.tts_generator(reference_text, str(output_path))
                
                if success and output_path.exists():
                    self._reference_cache[cache_key] = str(output_path)
                    logger.info(f"æ ‡å‡†éŸ³ç”ŸæˆæˆåŠŸ: {output_path}")
                    return str(output_path)
                else:
                    logger.warning("TTS ç”Ÿæˆå¤±è´¥")
            except Exception as e:
                logger.warning(f"TTS ç”Ÿæˆå¼‚å¸¸: {e}")
        
        logger.debug("æ— å¯ç”¨çš„æ ‡å‡†éŸ³")
        return None
    
    def score_pronunciation(
        self,
        audio_path: str,
        reference_text: str,
        reference_audio_path: Optional[str] = None,
        auto_generate_reference: bool = True
    ) -> Dict:
        """
        å¯¹ä¸­æ–‡å‘éŸ³è¿›è¡Œå®Œæ•´è¯„åˆ†ã€‚
        
        Args:
            audio_path: ç”¨æˆ·å½•éŸ³æ–‡ä»¶è·¯å¾„
            reference_text: æœŸæœ›çš„æ–‡æœ¬
            reference_audio_path: æ ‡å‡†éŸ³æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            auto_generate_reference: æ˜¯å¦è‡ªåŠ¨ç”Ÿæˆæ ‡å‡†éŸ³ï¼ˆå¦‚æœæœªæä¾›ï¼‰
        
        Returns:
            å®Œæ•´çš„è¯„åˆ†ç»“æœå­—å…¸
        """
        if not self.models_loaded:
            self.load_models()
        
        # è‡ªåŠ¨è·å–/ç”Ÿæˆæ ‡å‡†éŸ³
        if reference_audio_path is None and auto_generate_reference:
            reference_audio_path = self._get_or_generate_reference_audio(reference_text)
        
        has_reference = reference_audio_path is not None and Path(reference_audio_path).exists()
        
        if has_reference:
            logger.info("ä½¿ç”¨æ ‡å‡†éŸ³è¿›è¡Œè¯„åˆ†ï¼ˆé«˜ç²¾åº¦æ¨¡å¼ï¼‰")
        else:
            logger.info("æ— æ ‡å‡†éŸ³ï¼Œä½¿ç”¨æ¨¡å¼åˆ†æè¯„åˆ†")
        
        # ============ Task 1: æ‹¼éŸ³æ˜ å°„ ============
        logger.info("Task 1: æ–‡æœ¬ â†’ æ‹¼éŸ³...")
        pinyin_sequence = self.pinyin_mapper.text_to_pinyin(reference_text)
        
        if not pinyin_sequence:
            raise ValueError("å‚è€ƒæ–‡æœ¬ä¸­æ²¡æœ‰æ‰¾åˆ°ä¸­æ–‡å­—ç¬¦")
        
        # ============ Task 2: éŸ³é¢‘å¯¹é½ ============
        logger.info("Task 2: éŸ³é¢‘å¯¹é½ï¼ˆFunASRï¼‰...")
        if self.audio_aligner.is_available():
            alignment_results = self.audio_aligner.align_audio(
                audio_path,
                pinyin_sequence
            )
        else:
            warnings.warn("éŸ³é¢‘å¯¹é½ä¸å¯ç”¨ï¼Œä½¿ç”¨å‡åŒ€åˆ†é…")
            alignment_results = self._create_placeholder_alignment(
                audio_path,
                pinyin_sequence
            )
        
        # ============ Task 3: éŸ³é¢‘åˆ‡ç‰‡ ============
        logger.info("Task 3: éŸ³é¢‘åˆ‡ç‰‡...")
        sliced_results = self.audio_slicer.slice_audio(
            audio_path,
            alignment_results
        )
        
        # è°ƒè¯•ï¼šæ‰“å°ç”¨æˆ·éŸ³é¢‘åˆ‡ç‰‡ä¿¡æ¯
        print(f"\nğŸ“Š ç”¨æˆ·éŸ³é¢‘åˆ‡ç‰‡ç»“æœ ({len(sliced_results)} ä¸ª):")
        for i, seg in enumerate(sliced_results[:5]):  # åªæ‰“å°å‰5ä¸ª
            audio_len = len(seg.get('audio_segment', []))
            print(f"   [{i}] {seg.get('char')}: {seg.get('start', 0):.3f}s-{seg.get('end', 0):.3f}s, é‡‡æ ·ç‚¹={audio_len}")
        if len(sliced_results) > 5:
            print(f"   ... å…± {len(sliced_results)} ä¸ª")
        
        # å¦‚æœæœ‰æ ‡å‡†éŸ³ï¼Œå¯¹æ ‡å‡†éŸ³è¿›è¡Œ**ç‹¬ç«‹å¯¹é½å’Œåˆ‡ç‰‡**
        reference_segments = None
        if has_reference:
            try:
                # æ ‡å‡†éŸ³éœ€è¦ç‹¬ç«‹å¯¹é½ï¼Œä¸èƒ½ç”¨ç”¨æˆ·å½•éŸ³çš„æ—¶é—´æˆ³ï¼
                logger.info("å¯¹æ ‡å‡†éŸ³è¿›è¡Œç‹¬ç«‹å¯¹é½...")
                ref_alignment_results = self.audio_aligner.align_audio(
                    reference_audio_path,
                    pinyin_sequence
                )
                
                # è°ƒè¯•ï¼šæ‰“å°æ ‡å‡†éŸ³å¯¹é½ç»“æœ
                print(f"\nğŸ“Š æ ‡å‡†éŸ³å¯¹é½ç»“æœ ({len(ref_alignment_results)} ä¸ª):")
                for i, seg in enumerate(ref_alignment_results[:5]):
                    print(f"   [{i}] {seg.get('char')}: {seg.get('start', 0):.3f}s-{seg.get('end', 0):.3f}s")
                if len(ref_alignment_results) > 5:
                    print(f"   ... å…± {len(ref_alignment_results)} ä¸ª")
                
                # ç”¨æ ‡å‡†éŸ³è‡ªå·±çš„æ—¶é—´æˆ³åˆ‡ç‰‡
                reference_segments = self.audio_slicer.slice_audio(
                    reference_audio_path,
                    ref_alignment_results
                )
                
                # è°ƒè¯•ï¼šæ‰“å°æ ‡å‡†éŸ³åˆ‡ç‰‡ä¿¡æ¯
                print(f"\nğŸ“Š æ ‡å‡†éŸ³åˆ‡ç‰‡ç»“æœ ({len(reference_segments)} ä¸ª):")
                for i, seg in enumerate(reference_segments[:5]):
                    audio_len = len(seg.get('audio_segment', []))
                    print(f"   [{i}] {seg.get('char')}: é‡‡æ ·ç‚¹={audio_len}")
                
                logger.info(f"æ ‡å‡†éŸ³åˆ‡ç‰‡å®Œæˆ: {len(reference_segments)} æ®µ")
            except Exception as e:
                import traceback
                warnings.warn(f"æ ‡å‡†éŸ³åˆ‡ç‰‡å¤±è´¥: {e}")
                traceback.print_exc()
                reference_segments = None
        
        # ============ Task 4: å£°å­¦è¯„åˆ† ============
        logger.info("Task 4: å£°å­¦è¯„åˆ†ï¼ˆWavLMï¼‰...")
        print(f"\nğŸ”Š å¼€å§‹å£°å­¦è¯„åˆ†...")
        print(f"   reference_segments æ˜¯å¦å­˜åœ¨: {reference_segments is not None}")
        if reference_segments:
            print(f"   reference_segments æ•°é‡: {len(reference_segments)}")
        
        if self.acoustic_scorer.is_available():
            sliced_results = self.acoustic_scorer.score_segments(
                sliced_results,
                reference_segments=reference_segments
            )
            
            # æ‰“å°å£°å­¦è¯„åˆ†ç»“æœ
            print(f"\nğŸ“Š å£°å­¦è¯„åˆ†ç»“æœ:")
            for i, item in enumerate(sliced_results[:5]):
                print(f"   {item.get('char')}: acoustic_score={item.get('acoustic_score', 'N/A'):.4f}")
        else:
            for item in sliced_results:
                item["acoustic_score"] = 0.7
        
        # ============ Task 5: å£°è°ƒè¯„åˆ† ============
        logger.info("Task 5: å£°è°ƒè¯„åˆ†ï¼ˆF0 åˆ†æï¼‰...")
        print(f"\nğŸµ å¼€å§‹å£°è°ƒè¯„åˆ†...")
        
        if self.tone_scorer.is_available():
            sliced_results = self.tone_scorer.score_tones(
                sliced_results,
                reference_segments
            )
            
            # æ‰“å°å£°è°ƒè¯„åˆ†ç»“æœ
            print(f"\nğŸ“Š å£°è°ƒè¯„åˆ†ç»“æœ:")
            for i, item in enumerate(sliced_results[:5]):
                print(f"   {item.get('char')}: tone_score={item.get('tone_score', 'N/A'):.4f}, "
                      f"predicted={item.get('predicted_tone')}, expected={item.get('expected_tone')}")
        else:
            for item in sliced_results:
                item["tone_score"] = 0.7
                item["predicted_tone"] = 0
                item["expected_tone"] = 0
        
        # ============ Task 6: æ—¶é•¿è¯„åˆ† ============
        logger.info("Task 6: æ—¶é•¿è¯„åˆ†...")
        reference_durations = None
        if reference_segments:
            reference_durations = [
                seg.get('end', 0) - seg.get('start', 0) 
                for seg in reference_segments
            ]
        sliced_results = self.duration_scorer.score_durations(
            sliced_results,
            reference_durations
        )
        
        # ============ Task 7: åœé¡¿è¯„åˆ† ============
        logger.info("Task 7: åœé¡¿/æµç•…åº¦è¯„åˆ†...")
        sliced_results = self.pause_scorer.score_pauses(sliced_results)
        fluency_metrics = self.pause_scorer.calculate_overall_fluency(sliced_results)
        
        # ============ Task 8: é”™è¯¯åˆ†ç±» ============
        logger.info("Task 8: é”™è¯¯åˆ†ç±»...")
        if self.error_classifier.is_available():
            sliced_results = self.error_classifier.classify_errors(sliced_results)
        else:
            for item in sliced_results:
                item["errors"] = []
                item["error_probabilities"] = {}
        
        # ============ Task 9: ç»¼åˆè¯„åˆ† ============
        logger.info("Task 9: ç»¼åˆè¯„åˆ†...")
        final_results = self.final_scorer.calculate_final_scores(sliced_results)
        overall_metrics = self.final_scorer.calculate_overall_score(final_results)
        feedback = self.final_scorer.generate_feedback(final_results, overall_metrics)
        
        # æ‰“å°å„ç»´åº¦å¾—åˆ†æ±‡æ€»
        print(f"\n" + "="*60)
        print(f"ğŸ“Š å„å­—ç¬¦è¯¦ç»†å¾—åˆ†:")
        print(f"{'å­—ç¬¦':<4} {'å£°å­¦':<8} {'å£°è°ƒ':<8} {'æ—¶é•¿':<8} {'åœé¡¿':<8} {'æœ€ç»ˆ':<8}")
        print("-"*60)
        for item in final_results:
            char = item.get('char', '?')
            acoustic = item.get('acoustic_score', 0) * 100
            tone = item.get('tone_score', 0) * 100
            duration = item.get('duration_score', 0) * 100
            pause = item.get('pause_score', 0) * 100
            final = item.get('final_score', 0)
            print(f"{char:<4} {acoustic:<8.1f} {tone:<8.1f} {duration:<8.1f} {pause:<8.1f} {final:<8}")
        print("="*60)
        print(f"æ€»åˆ†: {overall_metrics['overall_score']}/100")
        print(f"="*60 + "\n")
        
        # æ·»åŠ é”™è¯¯æ”¹è¿›å»ºè®®
        all_errors = []
        for item in final_results:
            all_errors.extend(item.get('errors', []))
        
        if all_errors:
            error_suggestions = self.error_classifier.get_error_suggestions(
                list(set(all_errors))
            )
            feedback.extend(error_suggestions)
        
        # ç¼–è¯‘æœ€ç»ˆç»“æœ
        results = {
            "overall_score": overall_metrics["overall_score"],
            "character_scores": self._clean_results_for_output(final_results),
            "overall_metrics": overall_metrics,
            "fluency_metrics": fluency_metrics,
            "feedback": feedback,
            "reference_text": reference_text,
            "num_characters": len(final_results),
            "has_reference_audio": has_reference,
            "scoring_mode": "reference_comparison" if has_reference else "pattern_analysis"
        }
        
        logger.info(f"è¯„åˆ†å®Œæˆï¼æ€»åˆ†: {results['overall_score']}/100")
        
        return results
    
    def _clean_results_for_output(self, results: List[Dict]) -> List[Dict]:
        """
        æ¸…ç†ç»“æœï¼Œç§»é™¤ä¸éœ€è¦åºåˆ—åŒ–çš„æ•°æ®ï¼ˆå¦‚ numpy æ•°ç»„ï¼‰ã€‚
        
        Args:
            results: åŸå§‹ç»“æœåˆ—è¡¨
        
        Returns:
            æ¸…ç†åçš„ç»“æœåˆ—è¡¨
        """
        cleaned = []
        
        for item in results:
            cleaned_item = {}
            
            for key, value in item.items():
                # è·³è¿‡ numpy æ•°ç»„
                if key == 'audio_segment':
                    continue
                
                # è·³è¿‡å¤æ‚çš„ç‰¹å¾å­—å…¸
                if key == 'f0_features':
                    continue
                
                # è½¬æ¢ numpy ç±»å‹
                if hasattr(value, 'item'):
                    value = value.item()
                elif hasattr(value, 'tolist'):
                    value = value.tolist()
                
                cleaned_item[key] = value
            
            cleaned.append(cleaned_item)
        
        return cleaned
    
    def _create_placeholder_alignment(
        self,
        audio_path: str,
        pinyin_sequence: List[Dict]
    ) -> List[Dict]:
        """
        åˆ›å»ºå ä½å¯¹é½ç»“æœï¼ˆå½“ ASR ä¸å¯ç”¨æ—¶ï¼‰ã€‚
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            pinyin_sequence: æ‹¼éŸ³åºåˆ—
        
        Returns:
            å‡åŒ€åˆ†é…çš„å¯¹é½ç»“æœ
        """
        try:
            import librosa
            audio, _ = librosa.load(audio_path, sr=16000, mono=True)
            total_duration = len(audio) / 16000
        except:
            total_duration = len(pinyin_sequence) * 0.25
        
        num_chars = len(pinyin_sequence)
        char_duration = total_duration / num_chars if num_chars > 0 else 0
        
        alignment_results = []
        for i, item in enumerate(pinyin_sequence):
            alignment_results.append({
                "char": item["char"],
                "pinyin": item["pinyin"],
                "start": i * char_duration,
                "end": (i + 1) * char_duration,
                "score": 0.5
            })
        
        return alignment_results
    
    def clear_cache(self):
        """æ¸…é™¤æ ‡å‡†éŸ³ç¼“å­˜ã€‚"""
        self._reference_cache.clear()
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if self._temp_dir.exists():
            for file in self._temp_dir.glob("ref_*.wav"):
                try:
                    file.unlink()
                except:
                    pass
        
        logger.info("ç¼“å­˜å·²æ¸…é™¤")
    
    def is_available(self) -> bool:
        """
        æ£€æŸ¥æµæ°´çº¿æ˜¯å¦å¯ç”¨ã€‚
        
        Returns:
            True å¦‚æœåŸºæœ¬åŠŸèƒ½å¯ç”¨
        """
        return self.pinyin_mapper.is_available()