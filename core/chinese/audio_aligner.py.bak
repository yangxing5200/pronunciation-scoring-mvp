"""
Task 2: Audio Alignment (Forced Alignment)

Aligns audio with text pinyin to get timestamps for each character/phoneme.
Uses WhisperX for offline, GPU-optimized alignment.
"""

from typing import List, Dict, Optional
from pathlib import Path
import warnings
import numpy as np


class ChineseAudioAligner:
    """
    Aligns Chinese audio with text using WhisperX forced alignment.
    
    Provides character-level timestamps for Chinese pronunciation scoring.
    """
    
    # Minimum duration for a valid character segment (in seconds)
    MIN_CHAR_DURATION = 0.05  # 50ms minimum
    
    def __init__(self, device: Optional[str] = None):
        """
        Initialize audio aligner.
        
        Args:
            device: Device to use ('cuda' or 'cpu'), auto-detect if None
        """
        self.device = device
        self.whisperx_available = False
        self.model = None
        self.align_model = None
        self.align_metadata = None
        
        # Try to import and initialize WhisperX
        try:
            import torch
            if device is None:
                self.device = "cuda" if torch.cuda.is_available() else "cpu"
            
            import whisperx
            self.whisperx = whisperx
            self.whisperx_available = True
        except ImportError:
            warnings.warn(
                "WhisperX not available. Install with: "
                "pip install git+https://github.com/m-bain/whisperx.git"
            )
    
    def load_models(self, model_size: str = "base"):
        """
        Load WhisperX models for transcription and alignment.
        
        Args:
            model_size: Whisper model size ('tiny', 'base', 'small', 'medium', 'large')
        """
        if not self.whisperx_available:
            raise RuntimeError("WhisperX not available")
        
        # Load WhisperX transcription model
        compute_type = "float16" if self.device == "cuda" else "int8"
        self.model = self.whisperx.load_model(
            model_size,
            self.device,
            compute_type=compute_type
        )
        
        # Load alignment model for Chinese
        self.align_model, self.align_metadata = self.whisperx.load_align_model(
            language_code="zh",
            device=self.device
        )
        
        print(f"WhisperX models loaded on {self.device}")
    
    def align_audio(
        self,
        audio_path: str,
        pinyin_sequence: List[Dict[str, str]]
    ) -> List[Dict]:
        """
        Align audio with pinyin sequence to get character-level timestamps.
        
        Args:
            audio_path: Path to audio file
            pinyin_sequence: List from PinyinMapper with 'char' and 'pinyin' keys
        
        Returns:
            List of alignment results with timestamps:
            [
                {"char":"ä½ ", "pinyin":"ni3", "start":0.12, "end":0.36},
                {"char":"å¥½", "pinyin":"hao3", "start":0.36, "end":0.58},
                ...
            ]
        """
        if not self.whisperx_available:
            raise RuntimeError("WhisperX not available")
        
        if self.model is None or self.align_model is None:
            raise RuntimeError("Models not loaded. Call load_models() first.")
        
        # Load audio
        audio = self.whisperx.load_audio(audio_path)
        
        # Transcribe with WhisperX
        result = self.model.transcribe(
            audio,
            batch_size=16,
            language="zh"
        )
        
        # Align for character-level timestamps
        aligned_result = self.whisperx.align(
            result["segments"],
            self.align_model,
            self.align_metadata,
            audio,
            self.device,
            return_char_alignments=True  # Get character-level for Chinese
        )
        
        # Extract character-level timestamps
        char_timestamps = self._extract_char_timestamps(aligned_result)
        
        # Validate and fix timestamps
        char_timestamps = self._validate_timestamps(char_timestamps)
        
        # Match with expected pinyin sequence
        aligned_result_list = self._match_with_expected_sequence(
            char_timestamps,
            pinyin_sequence,
            audio_path
        )
        
        # Post-process to ensure all segments have valid durations
        aligned_result_list = self._ensure_valid_durations(aligned_result_list)
        
        return aligned_result_list
    
    def _extract_char_timestamps(self, aligned_result: Dict) -> List[Dict]:
        """
        Extract character timestamps from WhisperX alignment result.
        
        Args:
            aligned_result: WhisperX alignment result
        
        Returns:
            List of character timestamps
        """
        char_timestamps = []
        
        for segment in aligned_result.get("segments", []):
            for word_info in segment.get("words", []):
                # For Chinese, WhisperX provides character alignments
                if "chars" in word_info:
                    for char_info in word_info["chars"]:
                        char = char_info.get("char", "").strip()
                        if char:  # Only add non-empty characters
                            char_timestamps.append({
                                "char": char,
                                "start": char_info.get("start", 0.0),
                                "end": char_info.get("end", 0.0),
                                "score": char_info.get("score", 1.0)
                            })
                else:
                    # Fallback: if no character alignment, use word as character
                    char = word_info.get("word", "").strip()
                    if char:
                        char_timestamps.append({
                            "char": char,
                            "start": word_info.get("start", 0.0),
                            "end": word_info.get("end", 0.0),
                            "score": word_info.get("score", 1.0)
                        })
        
        return char_timestamps
    
    def _validate_timestamps(self, char_timestamps: List[Dict]) -> List[Dict]:
        """
        Validate and fix timestamp issues.
        
        Args:
            char_timestamps: Raw character timestamps
        
        Returns:
            Validated character timestamps
        """
        validated = []
        
        for i, ts in enumerate(char_timestamps):
            start = ts["start"]
            end = ts["end"]
            
            # Fix invalid timestamps
            if start < 0:
                start = 0.0
            if end < start:
                end = start + self.MIN_CHAR_DURATION
            if end - start < self.MIN_CHAR_DURATION:
                end = start + self.MIN_CHAR_DURATION
            
            validated.append({
                "char": ts["char"],
                "start": start,
                "end": end,
                "score": ts["score"]
            })
        
        return validated
    
    def _match_with_expected_sequence(
        self,
        char_timestamps: List[Dict],
        pinyin_sequence: List[Dict],
        audio_path: str
    ) -> List[Dict]:
        """
        Match detected characters with expected sequence.
        
        Args:
            char_timestamps: Detected character timestamps
            pinyin_sequence: Expected pinyin sequence
            audio_path: Path to audio file for fallback alignment
        
        Returns:
            Aligned results with matched characters
        """
        aligned_result_list = []
        
        # Create mapping of expected characters
        expected_chars = [item["char"] for item in pinyin_sequence]
        pinyin_map = {item["char"]: item["pinyin"] for item in pinyin_sequence}
        
        # Track which timestamps have been used
        used_timestamps = set()
        
        # Match detected characters with expected sequence
        for i, expected_char in enumerate(expected_chars):
            matched = False
            best_match = None
            best_score = 0.0
            best_idx = -1
            
            # Find best matching character in timestamps
            for j, ts in enumerate(char_timestamps):
                if j in used_timestamps:
                    continue
                    
                if ts["char"] == expected_char:
                    score = ts.get("score", 1.0)
                    if score > best_score:
                        best_match = ts
                        best_score = score
                        best_idx = j
                        matched = True
            
            if matched and best_match:
                # Use matched timestamp
                used_timestamps.add(best_idx)
                aligned_result_list.append({
                    "char": expected_char,
                    "pinyin": pinyin_map[expected_char],
                    "start": best_match["start"],
                    "end": best_match["end"],
                    "score": best_match.get("score", 1.0)
                })
            else:
                # No match found - use interpolation
                interpolated = self._interpolate_timestamp(
                    i,
                    len(expected_chars),
                    aligned_result_list,
                    audio_path
                )
                aligned_result_list.append({
                    "char": expected_char,
                    "pinyin": pinyin_map[expected_char],
                    "start": interpolated["start"],
                    "end": interpolated["end"],
                    "score": 0.3  # Low confidence for interpolated
                })
        
        return aligned_result_list
    
    def _interpolate_timestamp(
        self,
        index: int,
        total_chars: int,
        previous_alignments: List[Dict],
        audio_path: str
    ) -> Dict:
        """
        Interpolate timestamp for unmatched character.
        
        Args:
            index: Character index
            total_chars: Total number of characters
            previous_alignments: Previously aligned characters
            audio_path: Path to audio file
        
        Returns:
            Interpolated start and end times
        """
        try:
            import librosa
            # Get audio duration
            audio, _ = librosa.load(audio_path, sr=16000, mono=True)
            total_duration = len(audio) / 16000
        except:
            total_duration = total_chars * 0.25  # Fallback estimate
        
        if previous_alignments:
            # Use last known timestamp as reference
            last_end = previous_alignments[-1]["end"]
            remaining_chars = total_chars - index
            avg_duration = (total_duration - last_end) / max(1, remaining_chars)
            
            start = last_end
            end = start + max(self.MIN_CHAR_DURATION, avg_duration)
        else:
            # No previous alignments - use equal division
            avg_duration = total_duration / total_chars
            start = index * avg_duration
            end = start + max(self.MIN_CHAR_DURATION, avg_duration)
        
        return {
            "start": start,
            "end": min(end, total_duration)
        }
    
    def _ensure_valid_durations(
        self,
        aligned_results: List[Dict]
    ) -> List[Dict]:
        """
        Ensure all segments have valid durations.
        
        Args:
            aligned_results: Aligned results
        
        Returns:
            Results with validated durations
        """
        validated = []
        
        for i, result in enumerate(aligned_results):
            start = result["start"]
            end = result["end"]
            
            # Ensure minimum duration
            if end - start < self.MIN_CHAR_DURATION:
                end = start + self.MIN_CHAR_DURATION
            
            # Ensure no overlap with next segment
            if i < len(aligned_results) - 1:
                next_start = aligned_results[i + 1]["start"]
                if end > next_start:
                    # Adjust end to not overlap
                    end = next_start - 0.01
                    # But ensure minimum duration
                    if end - start < self.MIN_CHAR_DURATION:
                        # Adjust start backwards
                        start = end - self.MIN_CHAR_DURATION
            
            validated.append({
                **result,
                "start": max(0, start),
                "end": end
            })
        
        return validated
    
    def is_available(self) -> bool:
        """Check if WhisperX is available."""
        return self.whisperx_available