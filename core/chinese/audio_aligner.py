"""
Task 2: Audio Alignment (Forced Alignment) - FunASR Version

ä½¿ç”¨ FunASR (é˜¿é‡Œè¾¾æ‘©é™¢) è¿›è¡Œä¸­æ–‡è¯­éŸ³è¯†åˆ«å’Œå­—çº§åˆ«å¯¹é½ã€‚
FunASR çš„ Paraformer æ¨¡å‹å¯¹ä¸­æ–‡è¯†åˆ«å‡†ç¡®ç‡è¿œé«˜äº WhisperXã€‚

ä¼˜ç‚¹ï¼š
- ä¸­æ–‡è¯†åˆ«å‡†ç¡®ç‡é«˜ï¼ˆé˜¿é‡Œæµ·é‡ä¸­æ–‡æ•°æ®è®­ç»ƒï¼‰
- åŸç”Ÿæ”¯æŒå­—çº§åˆ«æ—¶é—´æˆ³
- æ”¯æŒ VADï¼ˆè¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼‰
- ç¦»çº¿éƒ¨ç½²ï¼Œæ¨¡å‹è‡ªåŠ¨ä¸‹è½½åˆ°æœ¬åœ°

å®‰è£…: pip install funasr modelscope
"""

from typing import List, Dict, Optional, Tuple
from pathlib import Path
import warnings
import numpy as np
import re


class ChineseAudioAligner:
    """
    ä½¿ç”¨ FunASR è¿›è¡Œä¸­æ–‡éŸ³é¢‘å¯¹é½ã€‚
    
    æä¾›å­—çº§åˆ«æ—¶é—´æˆ³ï¼Œç”¨äºåç»­çš„éŸ³é¢‘åˆ‡ç‰‡å’Œå‘éŸ³è¯„åˆ†ã€‚
    """
    
    # å­—ç¬¦æ®µæœ€å°/æœ€å¤§æ—¶é•¿ï¼ˆç§’ï¼‰
    MIN_CHAR_DURATION = 0.05  # 50ms
    MAX_CHAR_DURATION = 1.0   # 1s
    DEFAULT_CHAR_DURATION = 0.25  # 250msï¼ˆé»˜è®¤ä¼°è®¡å€¼ï¼‰
    
    def __init__(self, device: Optional[str] = None):
        """
        åˆå§‹åŒ–éŸ³é¢‘å¯¹é½å™¨ã€‚
        
        Args:
            device: ä½¿ç”¨çš„è®¾å¤‡ ('cuda' æˆ– 'cpu')ï¼ŒNone æ—¶è‡ªåŠ¨æ£€æµ‹
        """
        self.device = device
        self.funasr_available = False
        self.whisperx_available = False
        self.funasr_model = None
        self.whisperx_model = None
        self.align_model = None
        self.align_metadata = None
        
        # è‡ªåŠ¨æ£€æµ‹è®¾å¤‡
        try:
            import torch
            if device is None:
                self.device = "cuda" if torch.cuda.is_available() else "cpu"
            print(f"ğŸ–¥ï¸ ä½¿ç”¨è®¾å¤‡: {self.device}")
        except ImportError:
            self.device = "cpu"
        
        # æ£€æµ‹ FunASRï¼ˆé¦–é€‰ï¼‰
        try:
            from funasr import AutoModel
            self.AutoModel = AutoModel
            self.funasr_available = True
            print("âœ… FunASR å¯ç”¨ - æ¨èç”¨äºä¸­æ–‡è¯†åˆ«")
        except ImportError:
            warnings.warn(
                "FunASR ä¸å¯ç”¨ã€‚å®‰è£…å‘½ä»¤: pip install funasr modelscope\n"
                "FunASR çš„ä¸­æ–‡è¯†åˆ«å‡†ç¡®ç‡è¿œé«˜äº WhisperXã€‚"
            )
        
        # æ£€æµ‹ WhisperXï¼ˆå¤‡é€‰ï¼‰
        try:
            import whisperx
            self.whisperx = whisperx
            self.whisperx_available = True
            if not self.funasr_available:
                print("âš ï¸ ä½¿ç”¨ WhisperX ä½œä¸ºå¤‡é€‰ï¼ˆä¸­æ–‡å‡†ç¡®ç‡è¾ƒä½ï¼‰")
        except ImportError:
            if not self.funasr_available:
                warnings.warn(
                    "FunASR å’Œ WhisperX éƒ½ä¸å¯ç”¨ã€‚\n"
                    "è¯·å®‰è£… FunASR: pip install funasr modelscope"
                )
    
    def load_models(self, model_size: str = "base"):
        """
        åŠ è½½ ASR æ¨¡å‹ã€‚
        
        Args:
            model_size: æ¨¡å‹å¤§å°ï¼ˆä»…å¯¹ WhisperX æœ‰æ•ˆï¼‰
        """
        # ä¼˜å…ˆä½¿ç”¨ FunASR
        if self.funasr_available:
            try:
                print("ğŸ“¥ åŠ è½½ FunASR Paraformer æ¨¡å‹ï¼ˆé¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½ï¼‰...")
                
                # Paraformer-zh: é˜¿é‡Œå¼€æºçš„ä¸­æ–‡è¯­éŸ³è¯†åˆ«æ¨¡å‹
                # - æ”¯æŒå­—çº§åˆ«æ—¶é—´æˆ³
                # - è¯†åˆ«å‡†ç¡®ç‡é«˜
                # - æ˜¾å­˜å ç”¨çº¦ 2-3GB
                self.funasr_model = self.AutoModel(
                    model="paraformer-zh",           # ä¸­æ–‡ Paraformer
                    model_revision="v2.0.4",         # ç¨³å®šç‰ˆæœ¬
                    vad_model="fsmn-vad",            # è¯­éŸ³æ´»åŠ¨æ£€æµ‹
                    vad_model_revision="v2.0.4",
                    punc_model="ct-punc",            # æ ‡ç‚¹æ¢å¤
                    punc_model_revision="v2.0.4",
                    device=self.device
                )
                
                print(f"âœ… FunASR Paraformer æ¨¡å‹åŠ è½½å®Œæˆ (è®¾å¤‡: {self.device})")
                return
                
            except Exception as e:
                warnings.warn(f"FunASR åŠ è½½å¤±è´¥: {e}")
                self.funasr_available = False
                print("âš ï¸ å°è¯•ä½¿ç”¨ WhisperX ä½œä¸ºå¤‡é€‰...")
        
        # å¤‡é€‰: WhisperX
        if self.whisperx_available:
            try:
                compute_type = "float16" if self.device == "cuda" else "int8"
                self.whisperx_model = self.whisperx.load_model(
                    model_size,
                    self.device,
                    compute_type=compute_type
                )
                
                # åŠ è½½ä¸­æ–‡å¯¹é½æ¨¡å‹
                self.align_model, self.align_metadata = self.whisperx.load_align_model(
                    language_code="zh",
                    device=self.device
                )
                
                print(f"âš ï¸ WhisperX æ¨¡å‹åŠ è½½å®Œæˆ (è®¾å¤‡: {self.device})")
                print("   æ³¨æ„: WhisperX ä¸­æ–‡å‡†ç¡®ç‡è¾ƒä½ï¼Œå»ºè®®å®‰è£… FunASR")
                
            except Exception as e:
                raise RuntimeError(f"æ— æ³•åŠ è½½ä»»ä½• ASR æ¨¡å‹: {e}")
        else:
            raise RuntimeError(
                "æ²¡æœ‰å¯ç”¨çš„ ASR æ¨¡å‹ã€‚è¯·å®‰è£… FunASR:\n"
                "pip install funasr modelscope"
            )
    
    def align_audio(
        self,
        audio_path: str,
        pinyin_sequence: List[Dict[str, str]]
    ) -> List[Dict]:
        """
        å¯¹é½éŸ³é¢‘ä¸æ‹¼éŸ³åºåˆ—ï¼Œè·å–å­—çº§åˆ«æ—¶é—´æˆ³ã€‚
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            pinyin_sequence: PinyinMapper è¾“å‡ºçš„æ‹¼éŸ³åºåˆ—
                            [{'char': 'ä½ ', 'pinyin': 'ni3'}, ...]
        
        Returns:
            å¯¹é½ç»“æœåˆ—è¡¨:
            [
                {"char": "ä½ ", "pinyin": "ni3", "start": 0.12, "end": 0.36, "score": 0.95},
                {"char": "å¥½", "pinyin": "hao3", "start": 0.36, "end": 0.58, "score": 0.92},
                ...
            ]
        """
        if self.funasr_model is not None:
            return self._align_with_funasr(audio_path, pinyin_sequence)
        elif self.whisperx_model is not None:
            return self._align_with_whisperx(audio_path, pinyin_sequence)
        else:
            raise RuntimeError("æ¨¡å‹æœªåŠ è½½ã€‚è¯·å…ˆè°ƒç”¨ load_models()")
    
    def _align_with_funasr(
        self,
        audio_path: str,
        pinyin_sequence: List[Dict[str, str]]
    ) -> List[Dict]:
        """
        ä½¿ç”¨ FunASR è¿›è¡Œå¯¹é½ - æä¾›ç²¾ç¡®çš„å­—çº§åˆ«æ—¶é—´æˆ³ã€‚
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            pinyin_sequence: æœŸæœ›çš„æ‹¼éŸ³åºåˆ—
        
        Returns:
            å¯¹é½ç»“æœåˆ—è¡¨
        """
        # è·å–éŸ³é¢‘æ—¶é•¿
        audio_duration = self._get_audio_duration(audio_path)
        
        # FunASR è¯†åˆ«
        try:
            result = self.funasr_model.generate(
                input=audio_path,
                batch_size_s=300,          # æ‰¹å¤„ç†å¤§å°ï¼ˆç§’ï¼‰
                return_raw_text=False,     # è¿”å›ç»“æ„åŒ–ç»“æœ
            )
        except Exception as e:
            warnings.warn(f"FunASR è¯†åˆ«å¤±è´¥: {e}")
            return self._create_fallback_alignment(pinyin_sequence, audio_duration)
        
        # è§£æ FunASR ç»“æœ
        if not result or len(result) == 0:
            warnings.warn("FunASR è¿”å›ç©ºç»“æœ")
            return self._create_fallback_alignment(pinyin_sequence, audio_duration)
        
        # FunASR è¿”å›æ ¼å¼: [{'text': 'ä½ å¥½', 'timestamp': [[0, 250], [250, 500]], ...}]
        funasr_result = result[0] if isinstance(result, list) else result
        
        recognized_text = funasr_result.get('text', '')
        timestamps = funasr_result.get('timestamp', [])
        
        print(f"ğŸ¤ FunASR è¯†åˆ«ç»“æœ: {recognized_text}")
        print(f"   æœŸæœ›æ–‡æœ¬: {''.join([item['char'] for item in pinyin_sequence])}")
        print(f"   ğŸ” æ—¶é—´æˆ³æ•°é‡: {len(timestamps)}, è¯†åˆ«æ–‡æœ¬é•¿åº¦: {len(recognized_text)}")
        
        # å…³é”®ä¿®å¤ï¼šä¿ç•™æ¯ä¸ªå­—ç¬¦ï¼ˆå«æ ‡ç‚¹ï¼‰ä¸æ—¶é—´æˆ³çš„å¯¹åº”ï¼Œç„¶ååªæå–æ±‰å­—çš„æ—¶é—´æˆ³
        char_timestamps = self._build_char_timestamps_with_punctuation(
            recognized_text,
            timestamps,
            audio_duration
        )
        
        print(f"   ğŸ” æå–åˆ°çš„æ±‰å­—æ—¶é—´æˆ³æ•°é‡: {len(char_timestamps)}")
        
        # å°†è¯†åˆ«ç»“æœä¸æœŸæœ›åºåˆ—å¯¹é½
        aligned_results = self._align_with_expected_sequence(
            char_timestamps,
            pinyin_sequence,
            audio_duration
        )
        
        # åå¤„ç†ï¼šç¡®ä¿æ—¶é—´æˆ³æœ‰æ•ˆ
        aligned_results = self._postprocess_timestamps(aligned_results, audio_duration)
        
        return aligned_results
    
    def _build_char_timestamps_with_punctuation(
        self,
        recognized_text: str,
        timestamps: List,
        audio_duration: float
    ) -> List[Dict]:
        """
        ä»å¸¦æ ‡ç‚¹çš„è¯†åˆ«ç»“æœä¸­æå–æ±‰å­—çš„æ—¶é—´æˆ³ã€‚
        
        FunASR çš„ timestamp æ˜¯é’ˆå¯¹å®Œæ•´æ–‡æœ¬ï¼ˆå«æ ‡ç‚¹ï¼‰çš„ï¼Œ
        éœ€è¦å…ˆå»ºç«‹å­—ç¬¦-æ—¶é—´æˆ³å¯¹åº”ï¼Œå†ç­›é€‰å‡ºæ±‰å­—ã€‚
        
        Args:
            recognized_text: è¯†åˆ«åˆ°çš„å®Œæ•´æ–‡æœ¬ï¼ˆå«æ ‡ç‚¹ï¼‰
            timestamps: FunASR è¿”å›çš„æ—¶é—´æˆ³ [[start_ms, end_ms], ...]
            audio_duration: éŸ³é¢‘æ€»æ—¶é•¿ï¼ˆç§’ï¼‰
        
        Returns:
            ä»…åŒ…å«æ±‰å­—çš„æ—¶é—´æˆ³åˆ—è¡¨
        """
        char_timestamps = []
        
        # æ£€æŸ¥æ—¶é—´æˆ³æ•°é‡æ˜¯å¦ä¸æ–‡æœ¬é•¿åº¦åŒ¹é…
        if timestamps and len(timestamps) == len(recognized_text):
            # å®Œç¾åŒ¹é…ï¼šæ¯ä¸ªå­—ç¬¦ï¼ˆå«æ ‡ç‚¹ï¼‰éƒ½æœ‰æ—¶é—´æˆ³
            for i, char in enumerate(recognized_text):
                # åªä¿ç•™æ±‰å­—
                if re.match(r'[\u4e00-\u9fff]', char):
                    ts = timestamps[i]
                    if isinstance(ts, (list, tuple)) and len(ts) >= 2:
                        start = ts[0] / 1000.0  # æ¯«ç§’è½¬ç§’
                        end = ts[1] / 1000.0
                    else:
                        # æ—¶é—´æˆ³æ ¼å¼å¼‚å¸¸
                        continue
                    
                    char_timestamps.append({
                        'char': char,
                        'start': start,
                        'end': end,
                        'score': 0.9
                    })
            
            print(f"   âœ… ä» {len(recognized_text)} ä¸ªå­—ç¬¦ä¸­æå–äº† {len(char_timestamps)} ä¸ªæ±‰å­—æ—¶é—´æˆ³")
        
        elif timestamps:
            # æ—¶é—´æˆ³æ•°é‡ä¸åŒ¹é…ï¼Œå°è¯•å…¶ä»–ç­–ç•¥
            print(f"   âš ï¸ æ—¶é—´æˆ³æ•°é‡ ({len(timestamps)}) ä¸æ–‡æœ¬é•¿åº¦ ({len(recognized_text)}) ä¸åŒ¹é…")
            
            # æå–çº¯æ±‰å­—
            chinese_chars = self._extract_chinese_chars(recognized_text)
            
            # å¦‚æœæ—¶é—´æˆ³æ•°é‡ç­‰äºæ±‰å­—æ•°é‡ï¼Œç›´æ¥å¯¹åº”
            if len(timestamps) == len(chinese_chars):
                print(f"   âœ… æ—¶é—´æˆ³æ•°é‡ä¸æ±‰å­—æ•°é‡åŒ¹é…")
                for i, char in enumerate(chinese_chars):
                    ts = timestamps[i]
                    if isinstance(ts, (list, tuple)) and len(ts) >= 2:
                        start = ts[0] / 1000.0
                        end = ts[1] / 1000.0
                        char_timestamps.append({
                            'char': char,
                            'start': start,
                            'end': end,
                            'score': 0.85
                        })
            else:
                # ä½¿ç”¨å¤‡ç”¨ç­–ç•¥ï¼šåŸºäºæ—¶é—´èŒƒå›´å‡åŒ€åˆ†é…
                print(f"   âš ï¸ ä½¿ç”¨å‡åŒ€åˆ†é…ç­–ç•¥")
                char_timestamps = self._distribute_timestamps(
                    chinese_chars, timestamps, audio_duration
                )
        else:
            # æ²¡æœ‰æ—¶é—´æˆ³
            print(f"   âš ï¸ æ— æ—¶é—´æˆ³ä¿¡æ¯ï¼Œä½¿ç”¨å‡åŒ€åˆ†é…")
            chinese_chars = self._extract_chinese_chars(recognized_text)
            char_duration = audio_duration / max(1, len(chinese_chars))
            for i, char in enumerate(chinese_chars):
                char_timestamps.append({
                    'char': char,
                    'start': i * char_duration,
                    'end': (i + 1) * char_duration,
                    'score': 0.5
                })
        
        return char_timestamps
    
    def _build_char_timestamps(
        self,
        recognized_chars: List[str],
        timestamps: List,
        audio_duration: float
    ) -> List[Dict]:
        """
        æ„å»ºå­—ç¬¦-æ—¶é—´æˆ³æ˜ å°„ã€‚
        
        Args:
            recognized_chars: è¯†åˆ«åˆ°çš„ä¸­æ–‡å­—ç¬¦åˆ—è¡¨
            timestamps: FunASR è¿”å›çš„æ—¶é—´æˆ³ [[start_ms, end_ms], ...]
            audio_duration: éŸ³é¢‘æ€»æ—¶é•¿ï¼ˆç§’ï¼‰
        
        Returns:
            å­—ç¬¦æ—¶é—´æˆ³åˆ—è¡¨
        """
        char_timestamps = []
        
        # FunASR æ—¶é—´æˆ³æ˜¯æ¯«ç§’ï¼Œéœ€è¦è½¬æ¢ä¸ºç§’
        if timestamps and len(timestamps) == len(recognized_chars):
            # æ—¶é—´æˆ³æ•°é‡ä¸å­—ç¬¦æ•°é‡åŒ¹é…
            for i, char in enumerate(recognized_chars):
                ts = timestamps[i]
                if isinstance(ts, (list, tuple)) and len(ts) >= 2:
                    start = ts[0] / 1000.0  # æ¯«ç§’è½¬ç§’
                    end = ts[1] / 1000.0
                else:
                    # æ—¶é—´æˆ³æ ¼å¼å¼‚å¸¸ï¼Œä½¿ç”¨ä¼°è®¡å€¼
                    start = i * self.DEFAULT_CHAR_DURATION
                    end = (i + 1) * self.DEFAULT_CHAR_DURATION
                
                char_timestamps.append({
                    'char': char,
                    'start': start,
                    'end': end,
                    'score': 0.9  # FunASR è¯†åˆ«ç½®ä¿¡åº¦è¾ƒé«˜
                })
        
        elif timestamps and len(timestamps) > 0:
            # æ—¶é—´æˆ³æ•°é‡ä¸å­—ç¬¦æ•°é‡ä¸åŒ¹é…ï¼Œå°è¯•æ™ºèƒ½åˆ†é…
            # è¿™ç§æƒ…å†µå¯èƒ½æ˜¯ FunASR è¿”å›çš„æ˜¯è¯çº§åˆ«æ—¶é—´æˆ³
            total_chars = len(recognized_chars)
            
            if len(timestamps) == 1:
                # åªæœ‰ä¸€ä¸ªæ—¶é—´æˆ³æ®µï¼Œå¹³å‡åˆ†é…
                ts = timestamps[0]
                if isinstance(ts, (list, tuple)) and len(ts) >= 2:
                    segment_start = ts[0] / 1000.0
                    segment_end = ts[1] / 1000.0
                else:
                    segment_start = 0
                    segment_end = audio_duration
                
                char_duration = (segment_end - segment_start) / max(1, total_chars)
                
                for i, char in enumerate(recognized_chars):
                    char_timestamps.append({
                        'char': char,
                        'start': segment_start + i * char_duration,
                        'end': segment_start + (i + 1) * char_duration,
                        'score': 0.7
                    })
            else:
                # å¤šä¸ªæ—¶é—´æˆ³æ®µï¼Œå°è¯•æŒ‰æ¯”ä¾‹åˆ†é…
                char_timestamps = self._distribute_timestamps(
                    recognized_chars, timestamps, audio_duration
                )
        
        else:
            # æ²¡æœ‰æ—¶é—´æˆ³ï¼Œå¹³å‡åˆ†é…
            char_duration = audio_duration / max(1, len(recognized_chars))
            for i, char in enumerate(recognized_chars):
                char_timestamps.append({
                    'char': char,
                    'start': i * char_duration,
                    'end': (i + 1) * char_duration,
                    'score': 0.5
                })
        
        return char_timestamps
    
    def _distribute_timestamps(
        self,
        chars: List[str],
        timestamps: List,
        audio_duration: float
    ) -> List[Dict]:
        """
        å°†å¤šä¸ªæ—¶é—´æˆ³æ®µåˆ†é…ç»™å­—ç¬¦åˆ—è¡¨ã€‚
        
        å¤„ç† FunASR è¿”å›è¯çº§åˆ«æ—¶é—´æˆ³çš„æƒ…å†µã€‚
        """
        char_timestamps = []
        
        # å±•å¹³æ‰€æœ‰æ—¶é—´æˆ³
        all_starts = []
        all_ends = []
        
        for ts in timestamps:
            if isinstance(ts, (list, tuple)) and len(ts) >= 2:
                all_starts.append(ts[0] / 1000.0)
                all_ends.append(ts[1] / 1000.0)
        
        if not all_starts:
            # æ— æœ‰æ•ˆæ—¶é—´æˆ³ï¼Œå¹³å‡åˆ†é…
            char_duration = audio_duration / max(1, len(chars))
            for i, char in enumerate(chars):
                char_timestamps.append({
                    'char': char,
                    'start': i * char_duration,
                    'end': (i + 1) * char_duration,
                    'score': 0.5
                })
            return char_timestamps
        
        # è®¡ç®—æ€»æ—¶é—´èŒƒå›´
        total_start = min(all_starts)
        total_end = max(all_ends)
        total_duration = total_end - total_start
        
        # æŒ‰å­—ç¬¦æ•°å¹³å‡åˆ†é…
        char_duration = total_duration / max(1, len(chars))
        
        for i, char in enumerate(chars):
            char_timestamps.append({
                'char': char,
                'start': total_start + i * char_duration,
                'end': total_start + (i + 1) * char_duration,
                'score': 0.6
            })
        
        return char_timestamps
    
    def _align_with_expected_sequence(
        self,
        char_timestamps: List[Dict],
        pinyin_sequence: List[Dict],
        audio_duration: float
    ) -> List[Dict]:
        """
        å°†è¯†åˆ«ç»“æœä¸æœŸæœ›çš„æ‹¼éŸ³åºåˆ—å¯¹é½ã€‚
        
        ä½¿ç”¨åŠ¨æ€è§„åˆ’æ‰¾åˆ°æœ€ä¼˜åŒ¹é…ã€‚
        
        Args:
            char_timestamps: è¯†åˆ«åˆ°çš„å­—ç¬¦åŠæ—¶é—´æˆ³
            pinyin_sequence: æœŸæœ›çš„æ‹¼éŸ³åºåˆ—
            audio_duration: éŸ³é¢‘æ—¶é•¿
        
        Returns:
            å¯¹é½åçš„ç»“æœ
        """
        expected_chars = [item['char'] for item in pinyin_sequence]
        pinyin_map = {item['char']: item['pinyin'] for item in pinyin_sequence}
        
        recognized_chars = [item['char'] for item in char_timestamps]
        
        # å¦‚æœå®Œå…¨åŒ¹é…ï¼Œç›´æ¥ä½¿ç”¨
        if recognized_chars == expected_chars:
            print("âœ… è¯†åˆ«ç»“æœä¸æœŸæœ›å®Œå…¨åŒ¹é…")
            aligned_results = []
            for i, item in enumerate(pinyin_sequence):
                ts = char_timestamps[i]
                aligned_results.append({
                    'char': item['char'],
                    'pinyin': item['pinyin'],
                    'start': ts['start'],
                    'end': ts['end'],
                    'score': ts['score']
                })
            return aligned_results
        
        # ä½¿ç”¨ç¼–è¾‘è·ç¦»å¯¹é½
        print(f"âš ï¸ è¯†åˆ«ç»“æœä¸æœŸæœ›ä¸å®Œå…¨åŒ¹é…ï¼Œä½¿ç”¨å¯¹é½ç®—æ³•...")
        print(f"   è¯†åˆ«: {''.join(recognized_chars)}")
        print(f"   æœŸæœ›: {''.join(expected_chars)}")
        
        aligned_results = self._dtw_align(
            char_timestamps,
            pinyin_sequence,
            audio_duration
        )
        
        return aligned_results
    
    def _dtw_align(
        self,
        char_timestamps: List[Dict],
        pinyin_sequence: List[Dict],
        audio_duration: float
    ) -> List[Dict]:
        """
        ä½¿ç”¨ DTWï¼ˆåŠ¨æ€æ—¶é—´è§„æ•´ï¼‰å¯¹é½è¯†åˆ«ç»“æœå’ŒæœŸæœ›åºåˆ—ã€‚
        
        Args:
            char_timestamps: è¯†åˆ«åˆ°çš„å­—ç¬¦æ—¶é—´æˆ³
            pinyin_sequence: æœŸæœ›çš„æ‹¼éŸ³åºåˆ—
            audio_duration: éŸ³é¢‘æ—¶é•¿
        
        Returns:
            å¯¹é½åçš„ç»“æœï¼ˆä¿è¯ä¸ pinyin_sequence é•¿åº¦ç›¸åŒï¼‰
        """
        n_recognized = len(char_timestamps)
        n_expected = len(pinyin_sequence)
        
        if n_recognized == 0:
            # æ²¡æœ‰è¯†åˆ«åˆ°ä»»ä½•å†…å®¹ï¼Œä½¿ç”¨å‡åŒ€åˆ†é…
            return self._create_fallback_alignment(pinyin_sequence, audio_duration)
        
        # æ„å»ºç›¸ä¼¼åº¦çŸ©é˜µ
        # 1 = å®Œå…¨åŒ¹é…, 0 = ä¸åŒ¹é…
        similarity_matrix = np.zeros((n_expected, n_recognized))
        
        for i, expected_item in enumerate(pinyin_sequence):
            expected_char = expected_item['char']
            for j, recognized_item in enumerate(char_timestamps):
                recognized_char = recognized_item['char']
                if expected_char == recognized_char:
                    similarity_matrix[i, j] = 1.0
                else:
                    # å¯ä»¥æ‰©å±•ï¼šä½¿ç”¨æ‹¼éŸ³ç›¸ä¼¼åº¦ç­‰
                    similarity_matrix[i, j] = 0.0
        
        # ä½¿ç”¨è´ªå©ªåŒ¹é…æ‰¾åˆ°æ¯ä¸ªæœŸæœ›å­—ç¬¦çš„æœ€ä½³åŒ¹é…
        aligned_results = []
        used_indices = set()
        
        for i, expected_item in enumerate(pinyin_sequence):
            expected_char = expected_item['char']
            pinyin = expected_item['pinyin']
            
            # æ‰¾åˆ°æœ€ä½³åŒ¹é…ï¼ˆä¼˜å…ˆç²¾ç¡®åŒ¹é…ï¼Œå…¶æ¬¡ä½ç½®ç›¸è¿‘ï¼‰
            best_match_idx = -1
            best_score = -1
            
            for j in range(n_recognized):
                if j in used_indices:
                    continue
                
                sim = similarity_matrix[i, j]
                
                # è€ƒè™‘ä½ç½®å› ç´ ï¼ˆæœŸæœ›ä½ç½®ç›¸è¿‘çš„ä¼˜å…ˆï¼‰
                expected_position_ratio = i / max(1, n_expected - 1) if n_expected > 1 else 0.5
                actual_position_ratio = j / max(1, n_recognized - 1) if n_recognized > 1 else 0.5
                position_penalty = abs(expected_position_ratio - actual_position_ratio)
                
                # ç»¼åˆå¾—åˆ† = ç›¸ä¼¼åº¦ - ä½ç½®æƒ©ç½š
                score = sim - position_penalty * 0.3
                
                if score > best_score:
                    best_score = score
                    best_match_idx = j
            
            if best_match_idx >= 0 and similarity_matrix[i, best_match_idx] > 0.5:
                # æ‰¾åˆ°åŒ¹é…
                used_indices.add(best_match_idx)
                ts = char_timestamps[best_match_idx]
                aligned_results.append({
                    'char': expected_char,
                    'pinyin': pinyin,
                    'start': ts['start'],
                    'end': ts['end'],
                    'score': ts['score'] * similarity_matrix[i, best_match_idx]
                })
            else:
                # æ²¡æœ‰æ‰¾åˆ°åŒ¹é…ï¼Œä½¿ç”¨æ’å€¼
                interpolated_ts = self._interpolate_timestamp(
                    i, n_expected, aligned_results, char_timestamps, audio_duration
                )
                aligned_results.append({
                    'char': expected_char,
                    'pinyin': pinyin,
                    'start': interpolated_ts['start'],
                    'end': interpolated_ts['end'],
                    'score': 0.3  # ä½ç½®ä¿¡åº¦
                })
        
        return aligned_results
    
    def _interpolate_timestamp(
        self,
        index: int,
        total_chars: int,
        previous_alignments: List[Dict],
        char_timestamps: List[Dict],
        audio_duration: float
    ) -> Dict:
        """
        ä¸ºæœªåŒ¹é…çš„å­—ç¬¦æ’å€¼æ—¶é—´æˆ³ã€‚
        
        Args:
            index: å½“å‰å­—ç¬¦ç´¢å¼•
            total_chars: æ€»å­—ç¬¦æ•°
            previous_alignments: å·²å¯¹é½çš„ç»“æœ
            char_timestamps: æ‰€æœ‰è¯†åˆ«åˆ°çš„æ—¶é—´æˆ³
            audio_duration: éŸ³é¢‘æ€»æ—¶é•¿
        
        Returns:
            æ’å€¼çš„æ—¶é—´æˆ³ {'start': float, 'end': float}
        """
        # ç­–ç•¥1: åŸºäºå‰ä¸€ä¸ªå·²å¯¹é½å­—ç¬¦
        if previous_alignments:
            last_end = previous_alignments[-1]['end']
            remaining_duration = audio_duration - last_end
            remaining_chars = total_chars - index
            
            if remaining_chars > 0 and remaining_duration > 0:
                estimated_duration = min(
                    remaining_duration / remaining_chars,
                    self.MAX_CHAR_DURATION
                )
                estimated_duration = max(estimated_duration, self.MIN_CHAR_DURATION)
                
                return {
                    'start': last_end,
                    'end': last_end + estimated_duration
                }
        
        # ç­–ç•¥2: åŸºäºè¯†åˆ«åˆ°çš„æ—¶é—´æˆ³èŒƒå›´
        if char_timestamps:
            all_starts = [ts['start'] for ts in char_timestamps]
            all_ends = [ts['end'] for ts in char_timestamps]
            
            total_start = min(all_starts) if all_starts else 0
            total_end = max(all_ends) if all_ends else audio_duration
            
            char_duration = (total_end - total_start) / max(1, total_chars)
            char_duration = max(self.MIN_CHAR_DURATION, min(char_duration, self.MAX_CHAR_DURATION))
            
            return {
                'start': total_start + index * char_duration,
                'end': total_start + (index + 1) * char_duration
            }
        
        # ç­–ç•¥3: å‡åŒ€åˆ†é…
        char_duration = audio_duration / max(1, total_chars)
        char_duration = max(self.MIN_CHAR_DURATION, min(char_duration, self.MAX_CHAR_DURATION))
        
        return {
            'start': index * char_duration,
            'end': (index + 1) * char_duration
        }
    
    def _postprocess_timestamps(
        self,
        aligned_results: List[Dict],
        audio_duration: float
    ) -> List[Dict]:
        """
        åå¤„ç†æ—¶é—´æˆ³ï¼Œç¡®ä¿æœ‰æ•ˆæ€§ã€‚
        
        - ç¡®ä¿ start < end
        - ç¡®ä¿æ—¶é•¿åœ¨åˆç†èŒƒå›´å†…
        - ç¡®ä¿ä¸è¶…å‡ºéŸ³é¢‘è¾¹ç•Œ
        - ä¿®å¤é‡å 
        
        Args:
            aligned_results: å¯¹é½ç»“æœ
            audio_duration: éŸ³é¢‘æ—¶é•¿
        
        Returns:
            å¤„ç†åçš„ç»“æœ
        """
        if not aligned_results:
            return aligned_results
        
        processed = []
        
        for i, item in enumerate(aligned_results):
            start = item['start']
            end = item['end']
            
            # ç¡®ä¿ä¸ä¸ºè´Ÿæ•°
            start = max(0, start)
            end = max(0, end)
            
            # ç¡®ä¿ start < end
            if end <= start:
                end = start + self.MIN_CHAR_DURATION
            
            # ç¡®ä¿æ—¶é•¿åœ¨åˆç†èŒƒå›´
            duration = end - start
            if duration < self.MIN_CHAR_DURATION:
                end = start + self.MIN_CHAR_DURATION
            elif duration > self.MAX_CHAR_DURATION:
                end = start + self.MAX_CHAR_DURATION
            
            # ç¡®ä¿ä¸è¶…å‡ºéŸ³é¢‘è¾¹ç•Œ
            if end > audio_duration:
                end = audio_duration
                if start >= end:
                    start = max(0, end - self.MIN_CHAR_DURATION)
            
            processed.append({
                **item,
                'start': start,
                'end': end
            })
        
        # ä¿®å¤é‡å ï¼šç¡®ä¿æ¯ä¸ªå­—ç¬¦çš„ end <= ä¸‹ä¸€ä¸ªå­—ç¬¦çš„ start
        for i in range(len(processed) - 1):
            if processed[i]['end'] > processed[i + 1]['start']:
                # æœ‰é‡å ï¼Œå–ä¸­ç‚¹
                mid = (processed[i]['start'] + processed[i + 1]['end']) / 2
                processed[i]['end'] = mid
                processed[i + 1]['start'] = mid
        
        return processed
    
    def _create_fallback_alignment(
        self,
        pinyin_sequence: List[Dict],
        audio_duration: float
    ) -> List[Dict]:
        """
        åˆ›å»ºå¤‡ç”¨å¯¹é½ç»“æœï¼ˆå‡åŒ€åˆ†é…ï¼‰ã€‚
        
        å½“ ASR å¤±è´¥æ—¶ä½¿ç”¨ã€‚
        
        Args:
            pinyin_sequence: æœŸæœ›çš„æ‹¼éŸ³åºåˆ—
            audio_duration: éŸ³é¢‘æ—¶é•¿
        
        Returns:
            å‡åŒ€åˆ†é…çš„å¯¹é½ç»“æœ
        """
        n_chars = len(pinyin_sequence)
        if n_chars == 0:
            return []
        
        char_duration = audio_duration / n_chars
        char_duration = max(self.MIN_CHAR_DURATION, min(char_duration, self.MAX_CHAR_DURATION))
        
        results = []
        for i, item in enumerate(pinyin_sequence):
            results.append({
                'char': item['char'],
                'pinyin': item['pinyin'],
                'start': i * char_duration,
                'end': (i + 1) * char_duration,
                'score': 0.3  # ä½ç½®ä¿¡åº¦æ ‡è®°
            })
        
        return results
    
    def _extract_chinese_chars(self, text: str) -> List[str]:
        """
        ä»æ–‡æœ¬ä¸­æå–ä¸­æ–‡å­—ç¬¦ã€‚
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
        
        Returns:
            ä¸­æ–‡å­—ç¬¦åˆ—è¡¨
        """
        return re.findall(r'[\u4e00-\u9fff]', text)
    
    def _get_audio_duration(self, audio_path: str) -> float:
        """
        è·å–éŸ³é¢‘æ–‡ä»¶æ—¶é•¿ã€‚
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        
        Returns:
            æ—¶é•¿ï¼ˆç§’ï¼‰
        """
        try:
            import librosa
            audio, sr = librosa.load(audio_path, sr=16000, mono=True)
            return len(audio) / sr
        except Exception as e:
            warnings.warn(f"æ— æ³•è·å–éŸ³é¢‘æ—¶é•¿: {e}")
            return 5.0  # é»˜è®¤ 5 ç§’
    
    # ========== WhisperX å¤‡é€‰å®ç° ==========
    
    def _align_with_whisperx(
        self,
        audio_path: str,
        pinyin_sequence: List[Dict[str, str]]
    ) -> List[Dict]:
        """
        ä½¿ç”¨ WhisperX è¿›è¡Œå¯¹é½ï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼‰ã€‚
        
        æ³¨æ„: WhisperX çš„ä¸­æ–‡å¯¹é½å‡†ç¡®ç‡è¾ƒä½ã€‚
        """
        if self.whisperx_model is None or self.align_model is None:
            raise RuntimeError("WhisperX æ¨¡å‹æœªåŠ è½½")
        
        audio_duration = self._get_audio_duration(audio_path)
        
        try:
            # åŠ è½½éŸ³é¢‘
            audio = self.whisperx.load_audio(audio_path)
            
            # è½¬å½•
            result = self.whisperx_model.transcribe(
                audio,
                batch_size=16,
                language="zh"
            )
            
            # å¯¹é½
            aligned_result = self.whisperx.align(
                result["segments"],
                self.align_model,
                self.align_metadata,
                audio,
                self.device,
                return_char_alignments=True
            )
            
            # æå–å­—ç¬¦æ—¶é—´æˆ³
            char_timestamps = self._extract_whisperx_char_timestamps(aligned_result)
            
            # ä¸æœŸæœ›åºåˆ—å¯¹é½
            aligned_results = self._align_with_expected_sequence(
                char_timestamps,
                pinyin_sequence,
                audio_duration
            )
            
            # åå¤„ç†
            aligned_results = self._postprocess_timestamps(aligned_results, audio_duration)
            
            return aligned_results
            
        except Exception as e:
            warnings.warn(f"WhisperX å¯¹é½å¤±è´¥: {e}")
            return self._create_fallback_alignment(pinyin_sequence, audio_duration)
    
    def _extract_whisperx_char_timestamps(self, aligned_result: Dict) -> List[Dict]:
        """
        ä» WhisperX ç»“æœä¸­æå–å­—ç¬¦æ—¶é—´æˆ³ã€‚
        """
        char_timestamps = []
        
        for segment in aligned_result.get("segments", []):
            for word_info in segment.get("words", []):
                if "chars" in word_info:
                    for char_info in word_info["chars"]:
                        char = char_info.get("char", "").strip()
                        if char and re.match(r'[\u4e00-\u9fff]', char):
                            char_timestamps.append({
                                'char': char,
                                'start': char_info.get('start', 0.0),
                                'end': char_info.get('end', 0.0),
                                'score': char_info.get('score', 0.5)
                            })
                else:
                    # æ²¡æœ‰å­—ç¬¦çº§å¯¹é½ï¼ŒæŒ‰è¯å¤„ç†
                    word = word_info.get("word", "").strip()
                    start = word_info.get("start", 0.0)
                    end = word_info.get("end", 0.0)
                    
                    chinese_chars = self._extract_chinese_chars(word)
                    if chinese_chars:
                        char_duration = (end - start) / len(chinese_chars)
                        for i, char in enumerate(chinese_chars):
                            char_timestamps.append({
                                'char': char,
                                'start': start + i * char_duration,
                                'end': start + (i + 1) * char_duration,
                                'score': word_info.get('score', 0.5)
                            })
        
        return char_timestamps
    
    def is_available(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„ ASR æ¨¡å‹ã€‚"""
        return self.funasr_available or self.whisperx_available